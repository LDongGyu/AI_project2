{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File IO\n",
    "\n",
    "Only File IO...\n",
    "\n",
    "You may not change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter.filedialog import askopenfilename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tkinter\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "tk_window = tkinter.Tk()\n",
    "cwd = os.getcwd()\n",
    "\n",
    "tr_data = pd.read_csv(askopenfilename(title='Choose your training data'))\n",
    "\n",
    "tr_ans = pd.read_csv(askopenfilename(title='Choose your training answer'))\n",
    "\n",
    "tr_ans = tr_ans.iloc[:, 0]\n",
    "\n",
    "ts_data = pd.read_csv(askopenfilename(title='Choose your test data'))\n",
    "\n",
    "tk_window.destroy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Algorithm\n",
    "\n",
    "Type your source code (Champion Algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# human resource \n",
    "\n",
    "# 전처리\n",
    "# tr_data['department'].unique()\n",
    "# tr_data['department']=np.where(tr_data['department']=='support','technical',tr_data['department'])\n",
    "# tr_data['department']=np.where(tr_data['department']=='IT','technical',tr_data['department'])\n",
    "# ts_data['department']=np.where(ts_data['department']=='support','technical',ts_data['department'])\n",
    "# ts_data['department']=np.where(ts_data['department']=='IT','technical',ts_data['department'])\n",
    "\n",
    "# tr_data['department'] = pd.factorize(tr_data['department'])[0]\n",
    "# ts_data['department'] = pd.factorize(ts_data['department'])[0]\n",
    "\n",
    "# cat_vars=['department','salary']\n",
    "# for var in cat_vars:\n",
    "#     cat_list='var'+'_'+var\n",
    "#     cat_list = pd.get_dummies(tr_data[var], prefix=var)\n",
    "#     hr1=tr_data.join(cat_list)\n",
    "#     tr_data=hr1\n",
    "    \n",
    "# tr_data.drop(tr_data.columns[[8,9]],axis=1,inplace=True)\n",
    "# tr_data.columns.values\n",
    "\n",
    "one_hot_encode_cols = tr_data.dtypes[tr_data.dtypes == np.object]  # filtering by string categoricals\n",
    "one_hot_encode_cols = one_hot_encode_cols.index.tolist()  # list of categorical fields\n",
    "\n",
    "for col in one_hot_encode_cols:\n",
    "   tr_data[col] = pd.Categorical(tr_data[col])\n",
    "tr_data = pd.get_dummies(tr_data, columns=one_hot_encode_cols)\n",
    "for col in one_hot_encode_cols:\n",
    "   ts_data[col] = pd.Categorical(ts_data[col])\n",
    "ts_data = pd.get_dummies(ts_data, columns=one_hot_encode_cols)\n",
    "\n",
    "# tr_data.drop(['department_IT','department_RandD','department_accounting','department_hr','department_management','department_marketing','department_product_mng','department_sales','department_support','department_technical'], axis=1, inplace=True)\n",
    "# tr_data.drop(['years_at_company','work_accident'], axis=1, inplace=True)\n",
    "# ts_data.drop(['years_at_company','work_accident'], axis=1, inplace=True)\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', module='sklearn')\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# msc = MinMaxScaler()\n",
    "# msc.fit(tr_data)\n",
    "# scaled_X_data = pd.DataFrame(msc.transform(tr_data),  # this is an np.array, not a dataframe.\n",
    "#                     columns=tr_data.columns)\n",
    "\n",
    "PCAinst = PCA(n_components=7)\n",
    "PCAinst.fit(tr_data)\n",
    "\n",
    "tr_data = PCAinst.transform(tr_data)\n",
    "ts_data = PCAinst.transform(ts_data)\n",
    "\n",
    "\n",
    "# svd = TruncatedSVD(n_components=7)\n",
    "# svd.fit(tr_data)\n",
    "\n",
    "# tr_data = svd.transform(tr_data)\n",
    "# ts_data = svd.transform(ts_data)\n",
    "\n",
    "# kpca = KernelPCA(n_components=6, kernel='rbf', gamma=1.0)\n",
    "# kpca.fit(tr_data)\n",
    "\n",
    "# tr_data = kpca.transform(tr_data)\n",
    "# ts_data = kpca.transform(ts_data)\n",
    "# tr_data = PCAinst.fit_transform(tr_data)\n",
    "# human resource model\n",
    "# model = RandomForestClassifier(n_estimators=2000, random_state=0, n_jobs=-1)\n",
    "# model = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "# model = KNeighborsClassifier(n_neighbors=4)\n",
    "# model = XGBClassifier()\n",
    "\n",
    "# model = GradientBoostingClassifier(n_estimators = 1400, learning_rate=0.1600000000000001, max_depth = 5, random_state=0)\n",
    "# model = GradientBoostingClassifier(n_estimators = 1400, learning_rate=0.1600000000000001, max_depth = 5, random_state=0)\n",
    "model = GradientBoostingClassifier(n_estimators = 1400, learning_rate=0.16, max_depth = 5, random_state=0)\n",
    "model = model.fit(tr_data, tr_ans)\n",
    "\n",
    "y_pred = model.predict(ts_data)\n",
    "\n",
    "pred_df = pd.DataFrame(y_pred)\n",
    "\n",
    "pred_df.to_csv(\"output.csv\", mode='w')\n",
    "\n",
    "# End of Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy\n",
    "\n",
    "Only for check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6398799599866623\n"
     ]
    }
   ],
   "source": [
    "def accuracy(real, predict):\n",
    "    return sum(real == predict) / float(real.shape[0])\n",
    "\n",
    "tk_window = tkinter.Tk()\n",
    "cwd = os.getcwd()\n",
    "ts_ans = pd.read_csv(askopenfilename(title='Choose your test answer'))\n",
    "ts_ans = ts_ans.iloc[:, 0]\n",
    "tk_window.destroy()\n",
    "\n",
    "print(accuracy(ts_ans, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
